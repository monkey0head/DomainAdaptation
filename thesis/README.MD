**Сроки**
Работу надо сдать до 25 мая, защита 8 июня. Я честно верила в доделку до начала июня, но зря. Поэтому числа 15-20 я пришлю почитать работу. 
Она будет небольшой, т.к. требований по объему у нас, кажется, нет, и работы прошлых лет по 20-35 листов встречаются.

Я пока не нашла никакого интересного датасета, хочу попробовать для начала поэкспериментировать с архитектурами на office, вдруг получится добиться разультатов лучше, чем в оригинальных статьях.
Тогда буду думать, что у меня в работе научная новизна)

**Глобальный план**

Попробовать добиться на DANN результатов лучше, чем в статье (по одному домену с ResNet уже получилось). Или хотя бы оценить влияние отдельных элементов архитектуры на результаты. 
Потом попробовать поэкспериментировать с SPL, подавая ему на вход фичи из ResNet и DANN в различных его вариациях. 

**План экспериментов:**

Все эксперименты будут на amazon->webcam, и может быть, если успеется, webcam->amazon, потому что webcam-dslr и обратно и так очень похожи и хорошо приближаются без domain adaptation, а amazon-dslr и обратно ведут себя примерно как amazon-webcam, но не рассматривались в оригинальной статье про DANN. 
1) Сделать FineTuning ResNet и AlexNet на source domain и оценить качество на target domain как бейзлайн  

`сделано для части доменов, проблем не будет`

**DANN**

1) Воспроизвести DANN на AlexNet и Resnet

`сделано для части доменов, качество хуже, чем в статье, но как baseline для дальнейших экспериментов пойдет`
1) Поэкспериментировать с разморозкой сверточных слоев на AlexNet, Resnet:
    * Не размораживать
    * Размораживать одну, две, три последних свертки
    
    `сделано для части доменов, при разморозке сверток качество на target сначала хорошо растет, потом быстро начинает падать. Гипотеза - domain loss слишком сильно воздействует на фичи, чтобы они были одинаковыми, что делает фичи target-домена менее пригодными для классификации. Возможные варианты решения - перевзвешивать loss (п.5 и п.4, добавить adaptation block)`
    * Размораживать, устанавливая разный Learning Rate для слоев классификатора и feature extractor
    
    `не делала пока, сначала попробую п. 4, 5`
1) Поэкспериментировать с архитектурой классификатора на AlexNet, ResNet
    * Сделать для ResNet классификатор как у AlexNet (по дефолту там 1 полносвязный слой). Дальше буду называть его rich classifier.
    
    `сделала сразу с ADAPTATION_BLOCK, качество улучшилось. нужно теперь разделить влияние adaptation block и просто увеличение числа слоев классификатора`
    
    * Добавить ADAPTATION_BLOCK как в [статье](https://arxiv.org/pdf/1412.3474.pdf) и поэкспериментировать с его размером.
     
    `захардкодила, придется переделать, чтобы можно было делать эксперименты и с ADAPTATION_BLOCK, и без него`
    * Поэкспериментировать с разморозкой сверточных слоев с новым классификатором
    
    `пробовала, но тоже нужно будет переделать, чтобы оценить, где влияние нового классификатора, а где разморозки`
    * ? Возможно, поэкспериментировать с добавлением Dropout в классификатор и доменный классификатор
    
    `оставлю на потом`
1) Поэкспериментировать с соотношением Domain Loss и Classification Loss для разных архитектур DANN с разморозкой сверток

`это уже точно работает. при соотношении 1.5-1.9 classification loss и 0.5-0.1 domain loss качество на target заметно растет`

**Результаты запусков [тут](https://app.wandb.ai/monkey_head/domain_adaptation)**, но там уже помойка и нужно очень постараться, чтобы найти что-то конкретное :(


**SPL**
[Статья](https://arxiv.org/pdf/1911.07982.pdf)
[Код](https://github.com/hellowangqian/domain-adaptation-capls)

Это та самая статья с кодом на матбале, которую я рассказывала. Алгоритм принимает на вход эмбеддинги изображений (фичи из Resnet) и в несколько итераций проектирует элементы в латентное подпространство, делает над ними k-means и псевдо-лейблинг, каждую итерацию все больше элементов снабжая псевдо-лейблами. 

Я не научилась писать на матлабе и не нашла сломанного матлаба, чтобы поставить его себе, но нашла друга с матлабом, который готов позапускать код из репозитория на моих данных))

План такой:
1) Получить embeddings доменов из ResNet, нормализовать и прогнать через SPL (baseline)
`пока не делала`
2) Сделать fine-tuning ResNet на source domain, и использовать SPL на эмбеддингах source, target
`попробовала, качество пока хуже, чем в статье, но я забыла про нормализацию данных`
3) Использовать SPL на эмбеддингах из пары лучших архитектур DANN на Resnet, например, базового DANN на Resnet с fine-tuning и DANN c rich classifier (для этой архитектуры можно попробовать брать эмбеддинги с разных слоев классификатора)
`не начинала, сначала нужно довести до ума эксперименты с DANN`

